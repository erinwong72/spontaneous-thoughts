# Lab Scratchpad for [[2023-08-01]]
## LJP
### Implementing Black Box Model
- Importing libraries → missing library “chardet”, which should be automatically installed… so I just decided to start from scratch and make a new environment
	- New document to refer to: [[Installing tensorflow with gpu]], putting all bugs regarding tensorflow into there
	- Turns out it was not the problem, resolve by doing:
```bash
pip install chardet
pip install --force-reinstall charset-normalizer==3.1.0
```
- Looking at their dataset preprocessing:
	1. They’re taking the full dataset and filtering it so that they get rid of any extremely high LJP values (>0)
	2. Setting y to the LJP values that are not > 0
	3. Dropping all columns except for semi-axis lengths of both ellipses, angles of the second ellipse, and the intercenter distance
		1. Hmm but why drop the angles of the first ellipsoid?
			- Seems like they set all of those to 0 and only varied the angles for the second ellipsoid
			- It makes sense because rotations are relative—they were able to save time
- They use a sequential tensorflow model, maybe I can try implementing it in functional API

### Implementing the PINN model
- Preprocessing data (so far, just working on the ljp_ground_truth-10000.csv file)
	- Following this tutorial: [Writing Custom Datasets, DataLoaders and Transforms — PyTorch Tutorials 2.0.1+cu117 documentation](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)
	- Wrote a class LJP_Dataset that will process the csv file and turn it into PyTorch dataset format
		- I got this error when trying to load it into the backbone model
			- `KeyError Traceback (most recent call last) Cell In[67], line 3 1 # testing dataloader 2 for i, data in enumerate(dataloader): ----> 3 print(data[i]) 4 break KeyError: 0`
			- Likely my problem—yup it is because I made the return class of the get_item function a dictionary instead of keeping it a dataframe ;-;
			- Trying to convert it into a numpy array instead, but since some columns have list values, the shapes don’t match
				- Manual padding using 0s
	- Converting to each value (x length, y length, z length) does the trick for solving that problem, but now it’s stuck on the weights
		- First it was datatype → so I made sure inputs were in float32
		- Now it’s the indices: too many indices for dimension 1
		- Fixed the problem: Have to index the whole batch instead of just the first “entry” of the batch
			- Also, the distance (d, under predicted) was finding Euclidean distance using the coordinates of `e2_center`, so I had to fix the indexing, and it could also be replaced with `center_d` 💀