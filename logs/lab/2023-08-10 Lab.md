Â« [[2023-08-09 Lab]] | [[2023-08-11 Lab]] Â» 
# Lab Scratchpad for [[2023-08-10]]

## LJP
- Practiced the presentation multiple times (almost 10 times) with Dylan until we were able to consistently keep it under 2 minutes (or around there)
### PINN
- The model finished running! (on the regular GPU) â†’ I probably need to run it for at least another 250 epochs so the loss can descend even lower than currently (1.853)
	- ![[Pasted image 20230810092032.png]]
- Modifying load function for ease of continuing training â†’ wowwww ðŸ¤© it worked on the first try!!! ðŸ¥³
	- Running based on checkpoint/saved model, for another 250 epochs to see if loss can improve even further
	- After running for 500 epochs (another 250 epochs), loss is still going down (now at 1.14)
		- ![[Pasted image 20230810154702.png]]
	- Time to run it for even longer! (another 250 epochs bc once the loss dips below 1, it should minimize pretty well due to L-BFGS)
		- Well it got below 1 (loss) and then proceeded to error out bc of a cannot divide by zero error (smh)
	- After 750 epochs, it started using L-BFGS but the loss went really high and now I need to train for another 250:
		- ![[Pasted image 20230810205906.png]]
		- I implemented a feature where if the loss is > 1, even if L-BFGS was used before, donâ€™t use it
## Fibrinogen
- My mdrun of the Ce domain alone finished! I extracted results and added them to the presentation
	- It looks so fugly ðŸ˜­
		- ![[Screenshot 2023-08-10 at 10.54.17 AM.png|525]]
	- Hopefully it resolves itself after I continue the run for 10ns
- Continued working on presentation, got rid of all the intro text (already done by the REUs) and made speaker notes

## Optic Glomeruli
### Building Model
- Continue regenerating the stimuli:
	- Fixed all of them and regenerated y (output versions)
- Iâ€™ll need to cut all of them to the shortest number of frames so that I can concatenate them into a numpy array â†’ 343 frames is the shortest
	- Seeing if cutting some frames will make a big difference â€” not really, so thatâ€™s good :D
- Also needed to make sure examples and labels were in the same order and shaped properly

> [!tip]
> When concatenating, numpy will concatenate across an *existing* axis (should be common sense tbh) but if you want to stack arrays on top of each other/side by side, you need to create a new dimension by reshaping into (1, somethingâ€¦).

- Just realized that by keeping spatial and temporal separate, I made my life harder, bc Iâ€™ll have to separate the input and then put it back together
	- Main problems are, of course, the shape of the arrays
- Finished building the model!
	- Training it might be a painâ€¦ â†’ kernel died, my computer too weak ;( 