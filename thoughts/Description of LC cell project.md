#essay 

Vision is a critical mode of perception that guides behavioral responses in many organisms. Feature detectors are neurons involved in the processing of visual information that selectively extract information from the environment, like edges, moving objects, etc. Although the features that are identified by detectors like those in the primary visual cortex (i.e. V1, V2) are widely known, the particular attributes of such features that are the drivers behind detection are not. As testing using static scenes and stimuli has proven to be inefficient at discovering which characteristics drive responses, the focus turns to the use of computational methods, such as deep learning, to simulate neuronal responses. The Drosophila visual system was chosen for this study as it shares many conserved mechanisms with higher organisms while having simpler anatomical structures. In particular, fruit flies possess well-studied feature detectors known as lobula columnar cells, which form a visual bottleneck between the retina and the central brain. The objective of this study was to build an interpretable model capable of predicting the responses of lobula columnar (LC) cells in the fruit fly brain, given a visual stimulus. Twelve models, each corresponding to one LC cell type, were trained on a self-compiled dataset consisting of thirty dynamic stimuli and the corresponding neuronal responses. An average correlation coefficient of 0.68 was found through the evaluation of the R-squared metric, indicating a moderate to strong correlation between predicted and ground truth neuronal responses. Furthermore, when heatmaps of linear filter weights for each model were plotted to confirm predictions and test model interpretability, findings were consistent with the predicted responses. These models, by balancing complexity and interpretability, allow for more efficient investigations into the mechanisms behind feature detection.